{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22487,
     "status": "ok",
     "timestamp": 1587789876709,
     "user": {
      "displayName": "COVID19 Segmentation",
      "photoUrl": "",
      "userId": "12351684125312759490"
     },
     "user_tz": -330
    },
    "id": "L3oxAJU9XI8A",
    "outputId": "9dfba9a4-e6b5-4989-fde2-94320dd52130"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 771,
     "status": "ok",
     "timestamp": 1587790515476,
     "user": {
      "displayName": "COVID19 Segmentation",
      "photoUrl": "",
      "userId": "12351684125312759490"
     },
     "user_tz": -330
    },
    "id": "WwG7zC4SCKng",
    "outputId": "b00b72ca-fdb8-41a8-f679-12d732bee93d"
   },
   "outputs": [],
   "source": [
    "%cd drive/My Drive/keras-u-net-master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28267,
     "status": "ok",
     "timestamp": 1587790715850,
     "user": {
      "displayName": "COVID19 Segmentation",
      "photoUrl": "",
      "userId": "12351684125312759490"
     },
     "user_tz": -330
    },
    "id": "zTuR6l89qb5N",
    "outputId": "2a465c93-e759-4783-abe5-9261e489a63a"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#Import proper libraries\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from skimage.io import imsave, imread\n",
    "from PIL import Image\n",
    "data_path = 'data/'\n",
    "#Set Image width and height\n",
    "image_rows = 512\n",
    "image_cols = 512\n",
    "\n",
    "#Function to create training data\n",
    "def create_train_data():\n",
    "    train_data_path = os.path.join(data_path, 'train/Image PP/')\n",
    "    train_data_Label_path = os.path.join(data_path, 'train/Label/')\n",
    "    images = os.listdir(train_data_path)\n",
    "    total = len(images)\n",
    "\n",
    "    imgs = np.ndarray((total, image_rows, image_cols), dtype=np.uint8)\n",
    "    imgs_mask = np.ndarray((total, image_rows, image_cols), dtype=np.uint8)\n",
    "\n",
    "    i = 0\n",
    "    print('-'*30)\n",
    "    print('Creating training images...')\n",
    "    print('-'*30)\n",
    "    for image_name in images:\n",
    "        img = imread(os.path.join(train_data_path, image_name), as_gray=True)\n",
    "        img_mask = imread(os.path.join(train_data_Label_path, image_name), as_gray=True)\n",
    "\n",
    "        img = np.array([img])\n",
    "        img_mask = np.array([img_mask])\n",
    "\n",
    "        imgs[i] = img\n",
    "        imgs_mask[i] = img_mask\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print('Done: {0}/{1} images'.format(i, total))\n",
    "        i += 1\n",
    "    print('Loading done.')\n",
    "\n",
    "    np.save('imgs_train.npy', imgs)\n",
    "    np.save('imgs_mask_train.npy', imgs_mask)\n",
    "    print('Saving to .npy files done.')\n",
    "\n",
    "#Function to load the training data\n",
    "def load_train_data():\n",
    "    imgs_train = np.load('imgs_train.npy')\n",
    "    imgs_mask_train = np.load('imgs_mask_train.npy')\n",
    "    return imgs_train, imgs_mask_train\n",
    "\n",
    "#Function to create the testing data\n",
    "def create_test_data():\n",
    "    train_data_path = os.path.join(data_path, 'test/Image PP')\n",
    "    images = os.listdir(train_data_path)\n",
    "    total = len(images)\n",
    "\n",
    "    imgs = np.ndarray((total, image_rows, image_cols), dtype=np.uint8)\n",
    "    imgs_id = np.ndarray((total, ), dtype=np.int32)\n",
    "\n",
    "    i = 0\n",
    "    print('-'*30)\n",
    "    print('Creating test images...')\n",
    "    print('-'*30)\n",
    "    for image_name in images:\n",
    "        img_id = int(image_name.split('.')[0])\n",
    "        img = imread(os.path.join(train_data_path, image_name), as_gray=True)\n",
    "\n",
    "        img = np.array([img])\n",
    "\n",
    "        imgs[i] = img\n",
    "        imgs_id[i] = img_id\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('Done: {0}/{1} images'.format(i, total))\n",
    "        i += 1\n",
    "    print('Loading done.')\n",
    "\n",
    "    np.save('imgs_test.npy', imgs)\n",
    "    np.save('imgs_id_test.npy', imgs_id)\n",
    "    print('Saving to .npy files done.')\n",
    "\n",
    "#Function to load the testing data    \n",
    "def load_test_data():\n",
    "    imgs_test = np.load('imgs_test.npy')\n",
    "    imgs_id = np.load('imgs_id_test.npy')\n",
    "    return imgs_test, imgs_id\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    create_train_data()\n",
    "    create_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6103274,
     "status": "ok",
     "timestamp": 1587796913204,
     "user": {
      "displayName": "COVID19 Segmentation",
      "photoUrl": "",
      "userId": "12351684125312759490"
     },
     "user_tz": -330
    },
    "id": "l-Ke6uUKqda4",
    "outputId": "89695b9e-9cb6-487d-89b3-563d74f264d0"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#Import proper libraries\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose, Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras import losses,metrics\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t  \n",
    "from data_preparation import load_train_data, load_test_data\n",
    "\n",
    "\n",
    "smooth = 1.\n",
    "\n",
    "#Function to define dice coefficient \n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "#Function to define dice coefficient loss\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return dice_coef(y_true, y_pred)\n",
    "\n",
    "#Set Image width and height\n",
    "img_w, img_h = (256, 256) \n",
    "\n",
    "#Define the main UNet model with VGG weights\n",
    "def unet(num_classes, input_shape, lr_init, lr_decay, vgg_weight_path=None):\n",
    "    img_input = Input(input_shape)\n",
    "\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), padding='same', name='block1_conv1')(img_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same', name='block1_conv2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    block_1_out = Activation('relu')(x)\n",
    "\n",
    "    x = MaxPooling2D()(block_1_out)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), padding='same', name='block2_conv1')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same', name='block2_conv2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    block_2_out = Activation('relu')(x)\n",
    "\n",
    "    x = MaxPooling2D()(block_2_out)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv1')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv3')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    block_3_out = Activation('relu')(x)\n",
    "\n",
    "    x = MaxPooling2D()(block_3_out)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv1')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv3')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    block_4_out = Activation('relu')(x)\n",
    "\n",
    "    x = MaxPooling2D()(block_4_out)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='block5_conv1')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='block5_conv2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='block5_conv3')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    for_pretrained_weight = MaxPooling2D()(x)\n",
    "    \n",
    "    #VGG-16 weights are loaded here\n",
    "    # Load pretrained weights.\n",
    "    if vgg_weight_path is not None:\n",
    "        vgg16 = Model(img_input, for_pretrained_weight)\n",
    "        vgg16.load_weights(vgg_weight_path, by_name=True)\n",
    "\n",
    "    # UP 1\n",
    "    x = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = concatenate([x, block_4_out])\n",
    "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # UP 2\n",
    "    x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = concatenate([x, block_3_out])\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # UP 3\n",
    "    x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = concatenate([x, block_2_out])\n",
    "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # UP 4\n",
    "    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = concatenate([x, block_1_out])\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # last conv\n",
    "    x = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    model = Model(img_input, x)\n",
    "    #Model compiled for Adam, Binary Entropy Loss and dice coefficient, accuracy and MAE used as Metrics\n",
    "    model.compile(optimizer=Adam(lr=lr_init, decay=lr_decay),loss='binary_crossentropy',metrics=[dice_coef,'acc', metrics.mae])\n",
    "    \n",
    "    return model\n",
    "#Function to reshape images for predictions\n",
    "def preprocess(imgs):\n",
    "    imgs_p = np.ndarray((imgs.shape[0], img_w, img_h), dtype=np.uint8)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_p[i] = resize(imgs[i], (img_h, img_w), preserve_range=True)\n",
    "\n",
    "    imgs_p = imgs_p[..., np.newaxis]\n",
    "    return imgs_p\n",
    "\n",
    "#Main function to train the model and predict the masks\n",
    "def train_and_predict():\n",
    "    print('Loading and preprocessing train data...')\n",
    "    imgs_train, imgs_mask_train = load_train_data()\n",
    "\n",
    "    imgs_train = preprocess(imgs_train)\n",
    "    imgs_mask_train = preprocess(imgs_mask_train)\n",
    "\n",
    "    imgs_train = imgs_train.astype('float32')\n",
    "    mean = np.mean(imgs_train)  # mean for data centering\n",
    "    std = np.std(imgs_train)  # std for data normalization\n",
    "\n",
    "    imgs_train -= mean\n",
    "    imgs_train /= std\n",
    "\n",
    "    imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "    imgs_mask_train /= 255.  # scale masks to [0, 1]\n",
    "    \n",
    "    model=unet(1,(256,256,1),1e-5,1e-4)\n",
    "    print(model.summary())\n",
    "    \n",
    "    #Model checkpoints saved and Validation loss used to monitor\n",
    "    model_checkpoint = ModelCheckpoint('unet_weights_150_Img_VGG.h5', monitor='val_loss', save_best_only=True)\n",
    "    print('Fitting model...')\n",
    "    hist=model.fit(imgs_train, imgs_mask_train, batch_size=16, nb_epoch=1000, verbose=1, shuffle=True,\n",
    "              validation_split=0.2,\n",
    "              callbacks=[model_checkpoint])\n",
    "\n",
    "    imgs_test, imgs_id_test = load_test_data()\n",
    "    imgs_test = preprocess(imgs_test)\n",
    "    imgs_test = imgs_test.astype('float32')\n",
    "    mean=np.mean(imgs_test)\n",
    "    std=np.std(imgs_test)\n",
    "    imgs_test -= mean\n",
    "    imgs_test /= std\n",
    "\n",
    "    model.load_weights('unet_weights_150_Img_VGG.h5')\n",
    "\n",
    "    print('Predicting masks on test data...')\n",
    "\n",
    "    imgs_mask_test = model.predict(imgs_test, verbose=1)\n",
    "    np.save('imgs_mask_test.npy', imgs_mask_test)\n",
    "    pred_dir = 'preds_VGG'\n",
    "\n",
    "    if not os.path.exists(pred_dir):\n",
    "      os.mkdir(pred_dir)\n",
    "\n",
    "    for image, image_id in zip(imgs_mask_test, imgs_id_test):\n",
    "      image = (image[:, :, 0] * 255.).astype(np.uint8)\n",
    "      imsave(os.path.join(pred_dir, str(image_id) + '_pred.png'), image)\n",
    "    \n",
    "    #Model history plotted for various metrics used\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pickle\n",
    "    model.load_weights('unet_weights_150_Img_VGG.h5')\n",
    "    l_v=plt.plot(hist.history['loss'], color='b')\n",
    "    vl_v=plt.plot(hist.history['val_loss'], color='r')\n",
    "    plt.title('Loss Curve')\n",
    "    pickle.dump(l_v, open('Loss_VGG.fig.pickle', 'wb')) # This is for Python 3 - py2 may need `file` instead of `open`\n",
    "    pickle.dump(vl_v, open('Val_Loss_VGG.fig.pickle', 'wb')) # This is for Python 3 - py2 may need `file` instead of `open`\n",
    "    plt.show()\n",
    "\n",
    "    d_v=plt.plot(hist.history['dice_coef'], color='b')\n",
    "    vd_v=plt.plot(hist.history['val_dice_coef'], color='r')\n",
    "    plt.title('Dice Coefficient Curve')\n",
    "    pickle.dump(d_v, open('Dice_VGG.fig.pickle', 'wb')) # This is for Python 3 - py2 may need `file` instead of `open`\n",
    "    pickle.dump(vd_v, open('Val_Dice_VGG.fig.pickle', 'wb')) # This is for Python 3 - py2 may need `file` instead of `open`\n",
    "    plt.show()\n",
    "\n",
    "    a_v=plt.plot(hist.history['acc'], color='b')\n",
    "    va_v=plt.plot(hist.history['val_acc'], color='r')\n",
    "    pickle.dump(a_v, open('Acc_VGG.fig.pickle', 'wb')) # This is for Python 3 - py2 may need `file` instead of `open`\n",
    "    pickle.dump(va_v, open('Val_Acc_VGG.fig.pickle', 'wb')) # This is for Python 3 - py2 may need `file` instead of `open`\n",
    "    plt.title('Accuracy Curve')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_and_predict()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "VGG16_UNet_Seg_COVID_Code.ipynb",
   "provenance": [
    {
     "file_id": "1KL5NV4_OPTf8OJ38KtOuYsEaXaxI0Qfl",
     "timestamp": 1587661745994
    },
    {
     "file_id": "1xcpy4oNB0-vKkoIVVGnDdQH7yiOwpF2W",
     "timestamp": 1587658971888
    },
    {
     "file_id": "1YM8N4A1CscUzjrD5DeQ29XlHN-ik3qzy",
     "timestamp": 1587636731778
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
