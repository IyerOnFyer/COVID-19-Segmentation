{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20323,
     "status": "ok",
     "timestamp": 1587811536565,
     "user": {
      "displayName": "COVID19 Segmentation",
      "photoUrl": "",
      "userId": "12351684125312759490"
     },
     "user_tz": -330
    },
    "id": "L3oxAJU9XI8A",
    "outputId": "f328cb5b-2215-4256-bd17-29c51829a60e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1806,
     "status": "ok",
     "timestamp": 1587811540304,
     "user": {
      "displayName": "COVID19 Segmentation",
      "photoUrl": "",
      "userId": "12351684125312759490"
     },
     "user_tz": -330
    },
    "id": "WwG7zC4SCKng",
    "outputId": "91ad1066-24da-41c9-becd-c134fc30a00c"
   },
   "outputs": [],
   "source": [
    "%cd drive/My Drive/keras-u-net-master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 119722,
     "status": "ok",
     "timestamp": 1587811661792,
     "user": {
      "displayName": "COVID19 Segmentation",
      "photoUrl": "",
      "userId": "12351684125312759490"
     },
     "user_tz": -330
    },
    "id": "zTuR6l89qb5N",
    "outputId": "629296d2-b95c-4f31-ab55-7490aadcc68c"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#Import proper libraries\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from skimage.io import imsave, imread\n",
    "from PIL import Image\n",
    "data_path = 'data/'\n",
    "\n",
    "#Set Image width and height\n",
    "image_rows = 512\n",
    "image_cols = 512\n",
    "\n",
    "#Function to create training data\n",
    "def create_train_data():\n",
    "    train_data_path = os.path.join(data_path, 'train/Image PP/')\n",
    "    train_data_Label_path = os.path.join(data_path, 'train/Label/')\n",
    "    images = os.listdir(train_data_path)\n",
    "    total = len(images)\n",
    "\n",
    "    imgs = np.ndarray((total, image_rows, image_cols), dtype=np.uint8)\n",
    "    imgs_mask = np.ndarray((total, image_rows, image_cols), dtype=np.uint8)\n",
    "\n",
    "    i = 0\n",
    "    print('-'*30)\n",
    "    print('Creating training images...')\n",
    "    print('-'*30)\n",
    "    for image_name in images:\n",
    "        img = imread(os.path.join(train_data_path, image_name), as_gray=True)\n",
    "        img_mask = imread(os.path.join(train_data_Label_path, image_name), as_gray=True)\n",
    "\n",
    "        img = np.array([img])\n",
    "        img_mask = np.array([img_mask])\n",
    "\n",
    "        imgs[i] = img\n",
    "        imgs_mask[i] = img_mask\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print('Done: {0}/{1} images'.format(i, total))\n",
    "        i += 1\n",
    "    print('Loading done.')\n",
    "\n",
    "    np.save('imgs_train.npy', imgs)\n",
    "    np.save('imgs_mask_train.npy', imgs_mask)\n",
    "    print('Saving to .npy files done.')\n",
    "\n",
    "#FUnction to load training data\n",
    "def load_train_data():\n",
    "    imgs_train = np.load('imgs_train.npy')\n",
    "    imgs_mask_train = np.load('imgs_mask_train.npy')\n",
    "    return imgs_train, imgs_mask_train\n",
    "\n",
    "#Function to create testing data\n",
    "def create_test_data():\n",
    "    train_data_path = os.path.join(data_path, 'test/Image PP')\n",
    "    images = os.listdir(train_data_path)\n",
    "    total = len(images)\n",
    "\n",
    "    imgs = np.ndarray((total, image_rows, image_cols), dtype=np.uint8)\n",
    "    imgs_id = np.ndarray((total, ), dtype=np.int32)\n",
    "\n",
    "    i = 0\n",
    "    print('-'*30)\n",
    "    print('Creating test images...')\n",
    "    print('-'*30)\n",
    "    for image_name in images:\n",
    "        img_id = int(image_name.split('.')[0])\n",
    "        img = imread(os.path.join(train_data_path, image_name), as_gray=True)\n",
    "\n",
    "        img = np.array([img])\n",
    "\n",
    "        imgs[i] = img\n",
    "        imgs_id[i] = img_id\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('Done: {0}/{1} images'.format(i, total))\n",
    "        i += 1\n",
    "    print('Loading done.')\n",
    "\n",
    "    np.save('imgs_test.npy', imgs)\n",
    "    np.save('imgs_id_test.npy', imgs_id)\n",
    "    print('Saving to .npy files done.')\n",
    "\n",
    "#Function to load testing data    \n",
    "def load_test_data():\n",
    "    imgs_test = np.load('imgs_test.npy')\n",
    "    imgs_id = np.load('imgs_id_test.npy')\n",
    "    return imgs_test, imgs_id\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    create_train_data()\n",
    "    create_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5834331,
     "status": "ok",
     "timestamp": 1587817861551,
     "user": {
      "displayName": "COVID19 Segmentation",
      "photoUrl": "",
      "userId": "12351684125312759490"
     },
     "user_tz": -330
    },
    "id": "l-Ke6uUKqda4",
    "outputId": "4b7a41a3-1258-49a5-b76b-bbce5f464689"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#Import proper libraries\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose, Activation, UpSampling2D, Add\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras import losses,metrics\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.initializers import RandomNormal\n",
    "\n",
    "from data_preparation import load_train_data, load_test_data\n",
    "\n",
    "\n",
    "smooth = 1.\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "img_w, img_h = (256, 256) \n",
    "                \n",
    "def conv(x, outsize, kernel_size, strides_=1, padding_='same', activation=None):\n",
    "    return Conv2D(outsize, kernel_size, strides=strides_, padding=padding_, kernel_initializer=RandomNormal(\n",
    "        stddev=0.001), use_bias=False, activation=activation)(x)\n",
    "\n",
    "\n",
    "def Bottleneck(x, size, downsampe=False):\n",
    "    residual = x\n",
    "\n",
    "    out = conv(x, size, 1, padding_='valid')\n",
    "    out = BatchNormalization(epsilon=1e-5, momentum=0.1)(out)\n",
    "    out = Activation('relu')(out)\n",
    "\n",
    "    out = conv(out, size, 3)\n",
    "    out = BatchNormalization(epsilon=1e-5, momentum=0.1)(out)\n",
    "    out = Activation('relu')(out)\n",
    "\n",
    "    out = conv(out, size * 4, 1, padding_='valid')\n",
    "    out = BatchNormalization(epsilon=1e-5, momentum=0.1)(out)\n",
    "\n",
    "    if downsampe:\n",
    "        residual = conv(x, size * 4, 1, padding_='valid')\n",
    "        residual = BatchNormalization(epsilon=1e-5, momentum=0.1)(residual)\n",
    "\n",
    "    out = Add()([out, residual])\n",
    "    out = Activation('relu')(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def BasicBlock(x, size, downsampe=False):\n",
    "    residual = x\n",
    "\n",
    "    out = conv(x, size, 3)\n",
    "    out = BatchNormalization(epsilon=1e-5, momentum=0.1)(out)\n",
    "    out = Activation('relu')(out)\n",
    "\n",
    "    out = conv(out, size, 3)\n",
    "    out = BatchNormalization(epsilon=1e-5, momentum=0.1)(out)\n",
    "\n",
    "    if downsampe:\n",
    "        residual = conv(x, size, 1, padding_='valid')\n",
    "        residual = BatchNormalization(epsilon=1e-5, momentum=0.1)(residual)\n",
    "\n",
    "    out = Add()([out, residual])\n",
    "    out = Activation('relu')(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def layer1(x):\n",
    "    x = Bottleneck(x, 64, downsampe=True)\n",
    "    x = Bottleneck(x, 64)\n",
    "    x = Bottleneck(x, 64)\n",
    "    x = Bottleneck(x, 64)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def transition_layer(x, in_channels, out_channels):\n",
    "    num_in = len(in_channels)\n",
    "    num_out = len(out_channels)\n",
    "    out = []\n",
    "\n",
    "    for i in range(num_out):\n",
    "        if i < num_in:\n",
    "            if in_channels[i] != out_channels[i]:\n",
    "                residual = conv(x[i], out_channels[i], 3)\n",
    "                residual = BatchNormalization(\n",
    "                    epsilon=1e-5, momentum=0.1)(residual)\n",
    "                residual = Activation('relu')(residual)\n",
    "                out.append(residual)\n",
    "            else:\n",
    "                out.append(x[i])\n",
    "        else:\n",
    "            residual = conv(x[-1], out_channels[i], 3, strides_=2)\n",
    "            residual = BatchNormalization(epsilon=1e-5, momentum=0.1)(residual)\n",
    "            residual = Activation('relu')(residual)\n",
    "            out.append(residual)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def branches(x, block_num, channels):\n",
    "    out = []\n",
    "    for i in range(len(channels)):\n",
    "        residual = x[i]\n",
    "        for j in range(block_num):\n",
    "            residual = BasicBlock(residual, channels[i])\n",
    "        out.append(residual)\n",
    "    return out\n",
    "\n",
    "\n",
    "def fuse_layers(x, channels, multi_scale_output=True):\n",
    "    out = []\n",
    "\n",
    "    for i in range(len(channels) if multi_scale_output else 1):\n",
    "        residual = x[i]\n",
    "        for j in range(len(channels)):\n",
    "            if j > i:\n",
    "                y = conv(x[j], channels[i], 1, padding_='valid')\n",
    "                y = BatchNormalization(epsilon=1e-5, momentum=0.1)(y)\n",
    "                y = UpSampling2D(size=2 ** (j - i))(y)\n",
    "                residual = Add()([residual, y])\n",
    "            elif j < i:\n",
    "                y = x[j]\n",
    "                for k in range(i - j):\n",
    "                    if k == i - j - 1:\n",
    "                        y = conv(y, channels[i], 3, strides_=2)\n",
    "                        y = BatchNormalization(epsilon=1e-5, momentum=0.1)(y)\n",
    "                    else:\n",
    "                        y = conv(y, channels[j], 3, strides_=2)\n",
    "                        y = BatchNormalization(epsilon=1e-5, momentum=0.1)(y)\n",
    "                        y = Activation('relu')(y)\n",
    "                residual = Add()([residual, y])\n",
    "\n",
    "        residual = Activation('relu')(residual)\n",
    "        out.append(residual)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def HighResolutionModule(x, channels, multi_scale_output=True):\n",
    "    residual = branches(x, 4, channels)\n",
    "    out = fuse_layers(residual, channels,\n",
    "                      multi_scale_output=multi_scale_output)\n",
    "    return out\n",
    "\n",
    "\n",
    "def stage(x, num_modules, channels, multi_scale_output=True):\n",
    "    out = x\n",
    "    for i in range(num_modules):\n",
    "        if i == num_modules - 1 and multi_scale_output == False:\n",
    "            out = HighResolutionModule(out, channels, multi_scale_output=False)\n",
    "        else:\n",
    "            out = HighResolutionModule(out, channels)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def hrnet_keras(input_size=(256, 256, 1)):\n",
    "    channels_2 = [32, 64]\n",
    "    channels_3 = [32, 64, 128]\n",
    "    channels_4 = [32, 64, 128, 256]\n",
    "    num_modules_2 = 1\n",
    "    num_modules_3 = 4\n",
    "    num_modules_4 = 3\n",
    "\n",
    "    inputs = Input(input_size)\n",
    "    x = conv(inputs, 64, 3, strides_=2)\n",
    "    x = BatchNormalization(epsilon=1e-5, momentum=0.1)(x)\n",
    "    x = conv(x, 64, 3, strides_=2)\n",
    "    x = BatchNormalization(epsilon=1e-5, momentum=0.1)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    la1 = layer1(x)\n",
    "    tr1 = transition_layer([la1], [256], channels_2)\n",
    "    st2 = stage(tr1, num_modules_2, channels_2)\n",
    "    tr2 = transition_layer(st2, channels_2, channels_3)\n",
    "    st3 = stage(tr2, num_modules_3, channels_3)\n",
    "    tr3 = transition_layer(st3, channels_3, channels_4)\n",
    "    st4 = stage(tr3, num_modules_4, channels_4, multi_scale_output=False)\n",
    "    up1 = UpSampling2D()(st4[0])\n",
    "    up1 = conv(up1, 32, 3)\n",
    "    up1 = BatchNormalization(epsilon=1e-5, momentum=0.1)(up1)\n",
    "    up1 = Activation('relu')(up1)\n",
    "    up2 = UpSampling2D()(up1)\n",
    "    up2 = conv(up2, 32, 3)\n",
    "    up2 = BatchNormalization(epsilon=1e-5, momentum=0.1)(up2)\n",
    "    up2 = Activation('relu')(up2)\n",
    "    final = conv(up2, 1, 1, padding_='valid', activation='sigmoid')\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=final)\n",
    "\n",
    "    model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=[dice_coef,'acc', tf.keras.metrics.MeanIoU(num_classes=2),metrics.mae])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def preprocess(imgs):\n",
    "    imgs_p = np.ndarray((imgs.shape[0], img_w, img_h), dtype=np.uint8)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_p[i] = resize(imgs[i], (img_h, img_w), preserve_range=True)\n",
    "\n",
    "    imgs_p = imgs_p[..., np.newaxis]\n",
    "    return imgs_p\n",
    "\n",
    "\n",
    "def train_and_predict():\n",
    "    print('Loading and preprocessing train data...')\n",
    "    imgs_train, imgs_mask_train = load_train_data()\n",
    "\n",
    "    imgs_train = preprocess(imgs_train)\n",
    "    imgs_mask_train = preprocess(imgs_mask_train)\n",
    "\n",
    "    imgs_train = imgs_train.astype('float32')\n",
    "    mean = np.mean(imgs_train)  # mean for data centering\n",
    "    std = np.std(imgs_train)  # std for data normalization\n",
    "\n",
    "    imgs_train -= mean\n",
    "    imgs_train /= std\n",
    "\n",
    "    imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "    imgs_mask_train /= 255.  # scale masks to [0, 1]\n",
    "    \n",
    "    #model=hrnet_keras('unet_weights_150_Img_VGG.h5')\n",
    "    model=hrnet_keras()\n",
    "    print(model.summary())\n",
    "    \n",
    "    model_checkpoint = ModelCheckpoint('unet_weights_150_Img_HR.h5', monitor='val_loss', save_best_only=True)\n",
    "    print('Fitting model...')\n",
    "    hist=model.fit(imgs_train, imgs_mask_train, batch_size=16, nb_epoch=1000, verbose=1, shuffle=True,\n",
    "              validation_split=0.2,\n",
    "              callbacks=[model_checkpoint])\n",
    "\n",
    "    imgs_test, imgs_id_test = load_test_data()\n",
    "    imgs_test = preprocess(imgs_test)\n",
    "    imgs_test = imgs_test.astype('float32')\n",
    "    mean=np.mean(imgs_test)\n",
    "    std=np.std(imgs_test)\n",
    "    imgs_test -= mean\n",
    "    imgs_test /= std\n",
    "\n",
    "    model.load_weights('unet_weights_150_Img_HR.h5')\n",
    "\n",
    "    print('Predicting masks on test data...')\n",
    "\n",
    "    imgs_mask_test = model.predict(imgs_test, verbose=1)\n",
    "    np.save('imgs_mask_test.npy', imgs_mask_test)\n",
    "    pred_dir = 'preds_HR'\n",
    "\n",
    "    if not os.path.exists(pred_dir):\n",
    "      os.mkdir(pred_dir)\n",
    "\n",
    "    for image, image_id in zip(imgs_mask_test, imgs_id_test):\n",
    "      image = (image[:, :, 0] * 255.).astype(np.uint8)\n",
    "      imsave(os.path.join(pred_dir, str(image_id) + '_pred.png'), image)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import pickle\n",
    "    model.load_weights('unet_weights_150_Img_HR.h5')\n",
    "    l_hr=plt.plot(hist.history['loss'], color='b')\n",
    "    vl_hr=plt.plot(hist.history['val_loss'], color='r')\n",
    "    plt.title('Loss Curve')\n",
    "    pickle.dump(l_hr, open('Loss_HR.fig.pickle', 'wb')) # This is for Python 3 - py2 may need `file` instead of `open`\n",
    "    pickle.dump(vl_hr, open('Val_Loss_HR.fig.pickle', 'wb')) # This is for Python 3 - py2 may need `file` instead of `open`\n",
    "    plt.show()\n",
    "\n",
    "    d_hr=plt.plot(hist.history['dice_coef'], color='b')\n",
    "    vd_hr=plt.plot(hist.history['val_dice_coef'], color='r')\n",
    "    plt.title('Dice Coefficient Curve')\n",
    "    pickle.dump(d_hr, open('Dice_HR.fig.pickle', 'wb')) # This is for Python 3 - py2 may need `file` instead of `open`\n",
    "    pickle.dump(vd_hr, open('Val_Dice_HR.fig.pickle', 'wb')) # This is for Python 3 - py2 may need `file` instead of `open`\n",
    "    plt.show()\n",
    "\n",
    "    a_hr=plt.plot(hist.history['acc'], color='b')\n",
    "    va_hr=plt.plot(hist.history['val_acc'], color='r')\n",
    "    plt.title('Accuracy Curve')\n",
    "    pickle.dump(a_hr, open('Acc_HR.fig.pickle', 'wb')) # This is for Python 3 - py2 may need `file` instead of `open`\n",
    "    pickle.dump(va_hr, open('Val_Acc_HR.fig.pickle', 'wb')) # This is for Python 3 - py2 may need `file` instead of `open`\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_and_predict()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "HRNet_UNet_Seg_COVID_Code.ipynb",
   "provenance": [
    {
     "file_id": "1FGt0mXkRvlLu1OBlw4QEwJZ6q5ICDlK8",
     "timestamp": 1587702923738
    },
    {
     "file_id": "1KL5NV4_OPTf8OJ38KtOuYsEaXaxI0Qfl",
     "timestamp": 1587661745994
    },
    {
     "file_id": "1xcpy4oNB0-vKkoIVVGnDdQH7yiOwpF2W",
     "timestamp": 1587658971888
    },
    {
     "file_id": "1YM8N4A1CscUzjrD5DeQ29XlHN-ik3qzy",
     "timestamp": 1587636731778
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
